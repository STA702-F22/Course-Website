<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>STA 601: Lecture 1</title>
    <meta charset="utf-8" />
    <meta name="author" content="Merlise Clyde" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/font-awesome/css/all.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <link rel="stylesheet" href="slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# STA 601: Lecture 1
## Basics of Bayesian Statistics
### Merlise Clyde

---










## Ingredients

--

(1)  **Prior Distribution**  `\(\pi(\theta)\)`  for unknown `\(\theta\)`

--

(2) **Likelihood Function**  `\({\cal{L}}(\theta \mid y ) \propto p(y \mid \theta)\)` (sampling model)


--

(3)  **Posterior Distribution** 

.block[
.small[
`$$\pi(\theta | y) = \frac{\pi(\theta)p(y \mid \theta)}{\int_{\Theta}\pi({\theta})p(y\mid {\theta}) \textrm{d}{\theta}} = \frac{\pi(\theta)p(y\mid\theta)}{p(y)}$$`
]]

--

(4) **Loss Function** Depends on what you want to report; estimate of `\(\theta\)`, predict future `\(Y_{n+1}\)`,  etc


---
## Posterior Depends on  Likelihoods

- Likelihood is defined up to a consant
.block[
.small[
$$c \, {\cal{L}}(\theta \mid Y) =  p(y \mid \theta) $$
]]

--

- Bayes' Rule

.block[
.small[
`$$\pi(\theta | y) = \frac{\pi(\theta)p(y \mid \theta)}{\int_{\Theta}\pi({\theta})p(y\mid {\theta}) \textrm{d}{\theta}} = 
\frac{\pi(\theta)c {\cal{L}}(\theta \mid y)}{\int_{\Theta}\pi({\theta})c{\cal{L}}(\theta \mid y) \textrm{d}{\theta}}  = 
\frac{\pi(\theta){\cal{L}}(\theta \mid y)}{m(y)}$$`
]
]

--

- `\(m(y)\)` is proportional to the marginal distribution of data  

.block[
.small[
`$$m(y) = \int_{\Theta}\pi({\theta}){\cal{L}}(\theta \mid y) \textrm{d}{\theta}$$`
]]

--

- marginal likelihood of this model or "evidence"

--

 **Note:** the marginal likelihood and maximized likelihood are _very_ different!

---
## Binomial Example

`$$Y \mid n, \theta \sim \textsf{Binomial}(n, \theta)$$`
.block[
.small[
`$$p(y \mid \theta) = {n \choose y} \theta^y(1-\theta)^{n-y}$$`
]
]

--

.block[
.small[
`$$\cal{L}(\theta \mid y) =  \theta^y(1-\theta)^{n-y}$$`
]
]

--

MLE `\(\hat{\theta}\)` of  Binomial is  `\(\bar{y} = y/n\)`  proportion of successes

--

Recall Derivation:

---
## Marginal Likelihood

.block[
.small[
`$$m(y) = \int_\Theta \cal{L}(\theta \mid y)  \pi(\theta) \textrm{d}\theta=  \int_\Theta \theta^y(1-\theta)^{n-y} \pi(\theta) \textrm{d}\theta$$`
]
]


--

"Averaging" likelihood over prior


&lt;img src="01-basics-of-bayes_files/figure-html/unnamed-chunk-2-1.png" style="display: block; margin: auto;" /&gt;

---
##   Binomial Example

- **Prior** `\(\theta \sim \textsf{U}(0,1)\)` or `\(\pi(\theta) = 1, \quad \textrm{for } \theta \in (0,1)\)`

--

- **Marginal**
.block[
.small[
$$
m(y)  =  \int_0^1 \theta^y(1-\theta)^{n-y}\, 1 \,\textrm{d}\theta 
$$
]
]

--

.block[
.small[
$$m(y) =  \int_0^1 \theta^{(y +1) - 1}(1-\theta)^{(n-y + 1) - 1}\, 1 \,\textrm{d}\theta ={B}(y + 1, n-y + 1) $$
]]


--

-  Special function known as the **beta function** (see Rudin)

.block[
.small[
$${B}(a, b) =  \int_0^1 \theta^{a - 1}(1-\theta)^{b - 1} \,\textrm{d}\theta $$
]]


--

**Posterior Distribution**



.block[
.small[
$$\pi(\theta \mid y ) = \frac{1}{B(y + 1,n - y + 1)} \theta^{(y+1)-1} (1-\theta)^{(n - y +1) -1} \quad \qquad\theta \mid y \sim \textsf{Beta}((y + 1, n - y + 1) $$
]
]


---
## Beta Prior Distributions

**Beta(a,b)** is a probability density function (pdf) on (0,1),

.block[
.small[
`$$\pi(\theta) = \frac{1}{B(a,b)} \theta^{a-1} (1-\theta)^{b -1}$$`
]
]



Use the "**kernel**" trick  `$$\pi(\theta \mid y) \propto \cal{L}(\theta \mid y) \pi(\theta)$$`

---
## Prior to Posterior Updating

- **Prior** `\(\textsf{Beta}(a, b)\)`


--

- **Posterior** `\(\textsf{Beta}(a + y, b +  n - y)\)`

--

- **Conjugate** prior &amp; posterior distribution are in the same family of distributions, (Beta)

--

- Simple updating of information from the prior to posterior
--

   + `\(a + b\)` "prior sample size" (number of trials in a hypothetical experiment)
--

   + `\(a\)`  "number of successes"
--

   + `\(b\)`   "number of failures"
   
--

-  Should be easy to do "prior elicitation " (process of choosing the prior hyperparamters)

---
### Summaries &amp; Properties

Recall that  for `\(\theta \sim \textsf{Beta}(a,b)\)`  `\(a + b = n_0\)`

.block[
.small[
$$\textsf{E}[\theta] = \frac{a}{a+b}  \equiv \theta_0 $$
]
]

--

Posterior mean 

.block[
.small[
$$\textsf{E}[\theta \mid y ] = \frac{a + y }{a+b +n}  \equiv \tilde{\theta} $$
]
]

--

Rewrite with MLE `\(\hat{\theta} = \bar{y} = \frac{y}{n}\)` and prior mean

--


.block[
.small[
`$$\textsf{E}[\theta \mid y ] = \frac{a + y }{a+b +n}  
= \frac{n_0}{n_0 + n} \theta_0  + \frac{n}{n_0 + n} \hat{\theta}$$`
]
]

--

Weighted average of prior mean and MLE where weight for `\(\theta_0 \propto n_0\)` and weight for `\(\hat{\theta} \propto n\)`

---
## Properties

.block[
.small[
`$$\tilde{\theta} = \frac{n_0}{n_0 + n} \theta_0  + \frac{n}{n_0 + n} \hat{\theta}$$`
]
]

 

- in finite samples we get **shrinkage**: posterior mean pulls the MLE toward the prior mean; amount depends on  prior sample size `\(n_0\)` and data sample size `\(n\)`

--

- **regularization** effect to reduce Mean Squared Error for estimation with small sample sizes and noisy data

--

   - introduces some bias (in the frequentist sense) due to prior mean `\(\theta_0\)` 

--
   - reduces variance  (bias-variance trade-off)

--

- helpful in the Binomial case, when sample size is small or `\(\theta_{\text{true}} \approx 0\)` (rare events) and `\(\hat{\theta} = 0\)`  (inbalanced categorical data)

--

- as we get more information from the data `\(n \to \infty\)` we have `\(\tilde{\theta} \to \hat{\theta}\)`  and **consistency** ! As `\(n \to \infty, \textsf{E}[\tilde{\theta}] \to \theta_{\text{true}}\)`
---
## Some possible prior densities

&lt;img src="01-basics-of-bayes_files/figure-html/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /&gt;


---
## Prior Choice

- Is the uniform prior `\(\textsf{Beta}(1,1)\)` non-informative?  

--

  - No- if `\(y = 0\)` (or `\(n\)`) sparse/rare events saying that we have a prior "historical" sample with  1 success and 1 failure  ( `\(a = 1\)` and `\(b = 1\)` ) can be very informative
  
--

-  What about a uniform prior on the log odds?  `\(\eta \equiv \log\left( \frac{\theta} {1 - \theta} \right)\)`?
  
  .block[
  .small[$$\pi(\eta) \propto 1, \qquad \eta \in \mathbb{R}$$]
  ]

--

  - Is this a **proper** prior distribution?

--

  - what would be induced measure for `\(\theta\)`?

--

  - Find Jacobian  
  
.block[
.small[$$\pi(\theta) \propto \theta^{-1} (1 - \theta)^{-1}, \qquad \theta \in (0,1) $$]
  ]

--

   - limiting case of a Beta `\(a \to 0\)` and `\(b \to 0\)` (Haldane's prior)

---
## Formal Bayes

- use of improper prior and turn the Bayesian crank

--

- calculate `\(m(y)\)` and renormalize likelihood times "improper prior" if `\(m(y)\)` is finite  

--

- formal posterior is `\(\textsf{Beta}(y, n-y)\)` and reasonable only if `\(y \neq 0\)` or `\(y \neq n\)` as `\(B(0, -)\)` and `\(B(-, 0)\)` (normalizing constant) are undefined!

--

- no shrinkage `\(\textsf{E}[\theta \mid y] = \frac{y}{n} = \tilde{\theta} = \hat{\theta}\)`

---
###  Invariance

Jeffreys argues that priors should be invariant to transformations to be non-informative

--

i.e. if we reparameterize with `\(\theta = h(\rho)\)` then the rule should be that

.block[
.small[
`$$\pi_\theta(\theta) = \left|\frac{ d \rho} {d \theta}\right| \pi_\rho(h^{-1}(\theta))$$` 
]
]

--

Jefferys' rule is to pick `\(\pi(\rho) \propto (I(\rho))^{1/2}\)`


--

Expected Fisher Information for `\(\rho\)`

.block[.small[
$$ I(\rho) = - \textsf{E} \left[ \frac {d^2 \log ({\cal{L}}(\rho))} {d^2 \rho} \right]$$
]]

--

For the Binomial example `\(\pi(\theta) \propto \theta^{-1/2} (1 - \theta)^{-1/2}\)`


--

Thus Jefferys' prior is a `\(\textsf{Beta}(1/2, 1/2)\)`

---

### Why ?

Chain Rule!

--

Find Jefferys' prior for `\(\theta\)`


--

Find information matrix for `\(\rho\)` from  `\(I(\theta)\)`

--

Show that the prior satisfies the invariance property that 


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
